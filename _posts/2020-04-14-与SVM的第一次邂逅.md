---
layout:     post
title:      与 SVM 的第一次邂逅
subtitle:   夏天的一次组会
date:       2020-04-14
author:     WC
header-img: img/svm-back.jpg
catalog: true
tags:                               #标签
    - machine learning
---


# 与 SVM 的一次邂逅

## SVM（support vector machine)

去年夏天，跟着台大李宏毅老师的视频学过一个月的machine learning。他喜欢用各种宝可梦（神奇宝贝）做为引子，深入浅出地讲解知识点。受其启发，正好组会又没啥可汇报，欲模仿之，对自己演讲能力小试一把。苦于形形色色的内容无从下手之际，实验室超哥嘬了一口烟，再缓缓吐出，缭绕白烟中仿似一名道骨仙人，说道：小伙子，我看你骨骼清奇，去试试SVM吧...

于是，作品诞生了：

<img src="https://i.loli.net/2020/04/14/WLjlVJBvc96wR1D.png" alt="幻灯片1.PNG" style="zoom:50%;" />

ppt的开头我放了唐代诗人贾岛的一首诗《寻隐者不遇》，此诗是贾岛到山中寻访一位隐者，可能有业务商谈，无奈山中云雾缭绕把道路遮蔽了，行程未果后贾岛有感而作。那它和SVM有什么关系呢？

暂时不予解答，待后文分析。

<img src="https://i.loli.net/2020/04/14/gnxRyEkYTMCPuZr.png" alt="幻灯片2.PNG" style="zoom:50%;" />

这是大纲，词汇量匮乏原因，至今仍感觉没有概括出精髓。两部分内容：为什么用SVM？SVM是个什么东西？

<img src="https://i.loli.net/2020/04/14/21nhOQVLizUklpc.png" alt="幻灯片3.PNG" style="zoom:50%;" />

<img src="https://i.loli.net/2020/04/14/hVXiuwB1nklmcQM.png" alt="幻灯片4.PNG" style="zoom: 50%;" />

当时有个做产品经理的同学发过来一份简历让我把把关，我一看觉得不得了，此人理论与工程能力兼具，将来必成大器。可惜到了我的故事里，你就要变成面试失败的小明。话说小明有天带着光环加持的简历去面试，面试官就问了一句：是否能找到一组参数使得SVM的训练误差为零？小明很惊诧，面试官居然会问如此基础的问题，这对他简直是一种侮辱。可是他答不上来，他无法证明。最终悲剧了，小明只能仰天长叹：曾经有一个大厂机会摆在我面前，可是我没能好好珍惜，如果上天再给我一次机会，我愿对你说三个字——学好SVM...

<img src="https://i.loli.net/2020/04/14/YeHLVMNcsSRlGby.png" alt="幻灯片5.PNG" style="zoom:50%;" />

那么在deep learning大行其道的今天，为什么还有不少研究在用SVM呢？其中一方面，deep learning本身还有不少局限性，这些瑕疵就像鸡蛋上的缝，只要存在就是不圆满的，传统方法就还有一席之地。另一方面，SVM背后的知识理论支撑是万千方法的本源之一，许多新算法不过是在其基础上的变体。所以打开SVM的内核一窥其中，对大家是有相当益处的。

<img src="https://i.loli.net/2020/04/14/WFpRtQAPGuk3s4V.png" alt="幻灯片6.PNG" style="zoom:50%;" />

<img src="https://i.loli.net/2020/04/14/Xs7mchYbiASoPqv.png" alt="幻灯片7.PNG" style="zoom:50%;" />

来看一个分类问题，这是《百面机器学习》书中一个例子。说桌上有两种不同颜色的小球，让你用一根木棒去分开它们，如上图情况，很容易就做到了。

<img src="https://i.loli.net/2020/04/14/VdAn5IOu2gNkKUW.png" alt="幻灯片8.PNG" style="zoom:50%;" />

到了另一种情况下，木棒将难以完成这项任务，你可能得找一根绳子才能分开不同颜色的小球。

<img src="https://i.loli.net/2020/04/14/REhF6HZWTdQb9uc.png" alt="幻灯片9.PNG" style="zoom:50%;" />

换个思路，发现当我们把小球投射到三维空间上，我们就能用一根“棍子”，一个平面把不同颜色小球分开。这里的“棍子”、“平面”在machine learning术语中都称为**线性分类器**，同理“绳子”即为**非线性分类器**。在解决分类问题中，直接拟合出一个非线性分类器是困难的，需要一个庞大复杂的模型。根据[奥卡姆剃刀定律](https://www.jiqizhixin.com/graph/technologies/8e94913e-1fd5-404c-b830-241995bae82e)我们更希望使用线性分类器去解决问题，那么首先，我们就得对数据进行一些处理，比如像上面例子，映射到高维空间。

<img src="https://i.loli.net/2020/04/14/c9YQqzUjtE6fRTk.png" alt="幻灯片10.PNG" style="zoom:50%;" />

对于这些线性分类器，我们将它们统一定义为：超平面(Hyperplane)，解析式为:
$$
f(x)=w^Tx+b
$$
这里的$\vec{w}$和$\vec{x}$均为多维向量，其中表示$\vec{x}$特征(features)，如人的高矮胖瘦等特征就由不同的$x_i$来表示，若干个特征构成了“人”这一个集合体，同理某张图片，某段一维信号也均有若干个特征所表示，这些特征共同构成了高维空间，我们所要做的就是通过调控一组权重，来寻找$\vec{w}$某个Hyperplane，将具有不同特性的数据集分开，$b$偏移量(bias)，是起阈值调控作用的标量，对output的数值起到影响。

<img src="https://i.loli.net/2020/04/15/DHz6l5cJNBQwbIO.png" alt="幻灯片11.PNG" style="zoom:50%;" />

如何评价Hyperplane的优劣呢？看$$Gap$$，$$Gap$$代表了不同特性数据集之间相近程度，我们希望越远越好。因此需要去maximize $$Gap$$，那么分类任务即演化成了不等式约束下的最优化问题。注意到$$Gap$$与 $$ {1}/{||w||} $$ 为共轭关系，于是我们需要maximize $$ {1}/{||w||}$$ 。



<img src="https://i.loli.net/2020/04/15/BbsSULNxMEY7u6l.png" alt="幻灯片12.PNG" style="zoom:50%;" />

那么直接求解就ok了吗？还不行，在寻找最优解之前，我们还需要将原问题转化为对偶问题。原因是对偶问题在运用拉格朗日乘数法求解时会更加方便，同时我们将引入SVM的大杀器：核映射法。

<img src="https://i.loli.net/2020/04/15/4UGONBvqCQR7HxK.png" alt="幻灯片13.PNG" style="zoom:50%;" />

<img src="https://i.loli.net/2020/04/15/ouZqc4tl2FBUvOQ.png" alt="幻灯片14.PNG" style="zoom:50%;" />

通过推导，我们将原极小极大问题转换成极大极小问题，在满足[KKT](https://zhuanlan.zhihu.com/p/38163970)条件下，原问题与对偶问题的最优解相等。具体理论可参考凸优化相关知识，篇幅与能力所限此处不做展开。

<img src="https://i.loli.net/2020/04/15/mngjIKuB8Qwp2qh.png" alt="幻灯片15.PNG" style="zoom:50%;" />

我画了一幅图帮助大家形象地理解对偶表示。假如你目前的处境是左图，你面对的问题是测量你脚底地板到楼下地板的直线距离，很显然，此问题难以解决，你无法观测楼下的情况。那么换个思路，假如你站在楼下地板，需要测量到天花板的直线距离，问题就要容易不少。而KKT条件则帮助你消除二楼地面的厚度，使两类问题的解无限接近。

<img src="https://i.loli.net/2020/04/15/CmBwyQF2ePaRv1o.png" alt="幻灯片16.PNG" style="zoom:50%;" />

KKT条件中，红色框住的部分决定了SVM的分类结果仅取决于支持向量(support vector)，这是SVM算法高效的重要原因。

<img src="https://i.loli.net/2020/04/15/apLd7JBxgGEqfei.png" alt="幻灯片17.PNG" style="zoom:50%;" />

<img src="https://i.loli.net/2020/04/15/tJzYe7dokGQBLfj.png" alt="幻灯片18.PNG" style="zoom:50%;" />

问题求解过程中运用了[SMO](https://zhuanlan.zhihu.com/p/29212107)算法，篇幅与能力所限，此处不展开说明。

<img src="https://i.loli.net/2020/04/15/UAJdVye1z6tI3qc.png" alt="幻灯片19.PNG" style="zoom:50%;" />

接下来是SVM大杀器：核映射法(kernel trick)。如前文所述，我们将原始数据集通过$$\Phi(\cdot)$$映射到高维空间，原数据变得线性可分。如下例子所示：

<img src="https://i.loli.net/2020/04/15/pmq2DHlsgczyY4V.png" alt="幻灯片20.PNG" style="zoom:50%;" />

<img src="https://i.loli.net/2020/04/15/9TSltBAs1vVI4GC.png" alt="幻灯片21.PNG" style="zoom:50%;" />

<img src="https://i.loli.net/2020/04/15/yg3E2LT4rlSHj9x.png" alt="幻灯片22.PNG" style="zoom:50%;" />

但我们发现，当原数据维度非常高(K很大)，$$\Phi(\cdot)$$映射后的空间范围将趋于无穷，计算将变得无比困难。

<img src="https://i.loli.net/2020/04/15/2KTkcLtWEOmM3q9.png" alt="幻灯片23.PNG" style="zoom:50%;" />

<img src="https://i.loli.net/2020/04/15/WvOgXpQtURAKawJ.png" alt="幻灯片24.PNG" style="zoom:50%;" />

核映射方法应运而生，由泰勒展式，我们通过某些特定核函数直接计算的所得即相当于通过$$\Phi(\cdot)$$映射到高维空间后计算的结果。核函数的出现减轻了将原数据映射到高维空间进行计算的负担。

<img src="https://i.loli.net/2020/04/15/rF138xQzk5ci6Bu.png" alt="幻灯片25.PNG" style="zoom:50%;" />

核函数的种类也及其丰富，常用的包括线性、多项式、高斯、sigmoid等函数核。不用情况运用不同核函数效果不一，如:当数据特性简单，易于区分，数据样本充分情况下，使用线性核函数即可求得较好解。当数据特性复杂，信号特征多样化，使用高斯核函数则可取的较好效果。具体任务场景具体分析。

<img src="https://i.loli.net/2020/04/15/uFgph1jisO9UQaz.png" alt="幻灯片26.PNG" style="zoom: 67%;" />

回到开头，当贾岛驻足山中，行路不知去向，他需要一台无人机，脱离地面的束缚，飞向天空，在更高维的世界里，找寻那条正确的山路。

